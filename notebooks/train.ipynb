{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-16T21:52:54.830538Z",
     "start_time": "2024-04-16T21:52:51.998124Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.data_loader.data_loader import BooksDataset\n",
    "from src.models.mm_model import MmModel\n",
    "from src.train import Trainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T21:52:54.834570Z",
     "start_time": "2024-04-16T21:52:54.831182Z"
    }
   },
   "id": "61317a2fbf783557",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Module 'scipy' has no attribute 'diags'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\Desktop\\LLMrec_ppd\\llmrec_ppd\\Lib\\site-packages\\scipy\\__init__.py:150\u001B[0m, in \u001B[0;36m__getattr__\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n",
      "\u001B[1;31mKeyError\u001B[0m: 'diags'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mBooksDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../data/netflix\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\LLMrec_ppd\\src\\data_loader\\data_loader.py:52\u001B[0m, in \u001B[0;36mBooksDataset.__init__\u001B[1;34m(self, data_dir, batch_size)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minteractions \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_pickle(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/train_mat\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minteractions_T \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minteractions\u001B[38;5;241m.\u001B[39mT\n\u001B[1;32m---> 52\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minteractions \u001B[38;5;241m=\u001B[39m \u001B[43mcsr_norm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minteractions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minteractions \u001B[38;5;241m=\u001B[39m matrix_to_tensor(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minteractions)\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minteractions_T \u001B[38;5;241m=\u001B[39m csr_norm(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minteractions_T)\n",
      "File \u001B[1;32m~\\Desktop\\LLMrec_ppd\\src\\data_loader\\data_loader.py:28\u001B[0m, in \u001B[0;36mcsr_norm\u001B[1;34m(csr_mat, mean_flag)\u001B[0m\n\u001B[0;32m     26\u001B[0m rowsum \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mpower(rowsum \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1e-8\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\u001B[38;5;241m.\u001B[39mflatten()\n\u001B[0;32m     27\u001B[0m rowsum[np\u001B[38;5;241m.\u001B[39misinf(rowsum)] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.\u001B[39m\n\u001B[1;32m---> 28\u001B[0m rowsum_diag \u001B[38;5;241m=\u001B[39m \u001B[43msp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdiags\u001B[49m(rowsum)\n\u001B[0;32m     29\u001B[0m colsum \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(csr_mat\u001B[38;5;241m.\u001B[39msum(\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m     30\u001B[0m colsum \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mpower(colsum \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1e-8\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\u001B[38;5;241m.\u001B[39mflatten()\n",
      "File \u001B[1;32m~\\Desktop\\LLMrec_ppd\\llmrec_ppd\\Lib\\site-packages\\scipy\\__init__.py:152\u001B[0m, in \u001B[0;36m__getattr__\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mglobals\u001B[39m()[name]\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[1;32m--> 152\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[0;32m    153\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModule \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscipy\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    154\u001B[0m     )\n",
      "\u001B[1;31mAttributeError\u001B[0m: Module 'scipy' has no attribute 'diags'"
     ]
    }
   ],
   "source": [
    "dataset = BooksDataset(data_dir=\"../data/netflix\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T21:52:58.252088Z",
     "start_time": "2024-04-16T21:52:57.676035Z"
    }
   },
   "id": "ee13077813f83521",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "MmModel(\n  (E0): Embedding(30553, 128)\n  (image_feat): Linear(in_features=512, out_features=128, bias=True)\n  (text_feat_dropout): Dropout(p=0.1, inplace=False)\n  (text_feat): Linear(in_features=768, out_features=128, bias=True)\n  (image_feat_dropout): Dropout(p=0.1, inplace=False)\n  (user_profiles): Linear(in_features=1536, out_features=128, bias=True)\n  (user_profiles_dropout): Dropout(p=0.1, inplace=False)\n  (book_attributes): Linear(in_features=1536, out_features=128, bias=True)\n  (book_attributes_dropout): Dropout(p=0.1, inplace=False)\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MmModel(n_users=dataset.n_users,n_items=dataset.n_items,adjacency_matrix=dataset.get_dataset(\"adjacency_matrix\"),interactions= dataset.get_dataset(\"interactions\") ,interactions_t= dataset.get_dataset(\"interactions_T\") ,image_embeddings_data=dataset.get_dataset(\"images\"),text_embeddings_data=dataset.get_dataset(\"text\"),embed_size=128,n_layers=3,user_profiles_data=dataset.get_dataset(\"user_profiles\"),book_attributes_data=dataset.get_dataset(\"books_attributes\"))\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T21:05:56.658498Z",
     "start_time": "2024-04-11T21:05:56.434661Z"
    }
   },
   "id": "fd0ffa6e74bd6c03",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-11 23:06:  PID: 7388\n",
      "2024-04-11 23:06:  \n",
      "Dataset             Shape                \n",
      "----------------------------------------\n",
      "images              (17366, 512)\n",
      "text                (17366, 768)\n",
      "user_profiles       (13187, 1536)\n",
      "books_attributes    (17366, 1536)\n",
      "train_dict          13187\n",
      "test_dict           5000\n",
      "val_dict            5000\n",
      "adjacency_matrix    30553\n",
      "interactions        13187\n",
      "\n",
      "Number of interactions: 68933\n",
      "Sparsity: 99.97%\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model,dataset=dataset,lr=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T21:06:03.399020Z",
     "start_time": "2024-04-11T21:06:01.907997Z"
    }
   },
   "id": "e7d567a61f623434",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.91it/s]\n",
      "100%|██████████| 3/3 [00:24<00:00,  8.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-11 23:06:  Epoch 0 Loss 5604.622565049392 Time 27.73566961288452\n",
      "2024-04-11 23:06:  \n",
      "precision: [0.00046  0.00043  0.000432]\n",
      "recall: [0.0046 0.0086 0.0216]\n",
      "ndcg: [0.00214707 0.00313305 0.00569635]\n",
      "hit_ratio: [0.0046 0.0086 0.0216]\n",
      "auc: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  5.81it/s]\n",
      "100%|██████████| 3/3 [00:24<00:00,  8.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-11 23:06:  Epoch 1 Loss 749.1023301344651 Time 26.76872420310974\n",
      "2024-04-11 23:06:  \n",
      "precision: [0.00056  0.00055  0.000416]\n",
      "recall: [0.0056 0.011  0.0208]\n",
      "ndcg: [0.00205755 0.00342935 0.00534125]\n",
      "hit_ratio: [0.0056 0.011  0.0208]\n",
      "auc: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  6.12it/s]\n",
      "100%|██████████| 3/3 [00:24<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-11 23:07:  Epoch 2 Loss 172.7341079711914 Time 26.810803651809692\n",
      "2024-04-11 23:07:  \n",
      "precision: [0.00058  0.00056  0.000484]\n",
      "recall: [0.0058 0.0112 0.0242]\n",
      "ndcg: [0.0029919  0.00433758 0.00692855]\n",
      "hit_ratio: [0.0058 0.0112 0.0242]\n",
      "auc: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  5.68it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "trainer.train(epochs=10,batch_size=1024)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-11T21:06:04.505381Z"
    }
   },
   "id": "77c25e8e9577ae11",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "def matrix_to_tensor(numpy_matrix):\n",
    "    sparse_tensor = torch.sparse_coo_tensor(torch.from_numpy(np.argwhere(numpy_matrix != 0).T),\n",
    "                                            torch.from_numpy(numpy_matrix[np.nonzero(numpy_matrix)]),\n",
    "                                            numpy_matrix.shape,dtype=torch.float32)\n",
    "    return sparse_tensor\n",
    "\n",
    "\n",
    "def csr_norm(csr_mat, mean_flag=False):  # TODO: check if this function exists in a python library\n",
    "    rowsum = np.array(csr_mat.sum(1))\n",
    "    rowsum = np.power(rowsum + 1e-8, -0.5).flatten()\n",
    "    rowsum[np.isinf(rowsum)] = 0.\n",
    "    rowsum_diag = sp.diags(rowsum)\n",
    "    colsum = np.array(csr_mat.sum(0))\n",
    "    colsum = np.power(colsum + 1e-8, -0.5).flatten()\n",
    "    colsum[np.isinf(colsum)] = 0.\n",
    "    colsum_diag = sp.diags(colsum)\n",
    "    if mean_flag == False:\n",
    "        return rowsum_diag * csr_mat * colsum_diag\n",
    "    else:\n",
    "        return rowsum_diag * csr_mat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T00:03:53.677057Z",
     "start_time": "2024-03-31T00:03:53.545409Z"
    }
   },
   "id": "841c1209973130c2",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = matrix_to_tensor(csr_norm(data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T00:04:36.786260Z",
     "start_time": "2024-03-31T00:04:03.797937Z"
    }
   },
   "id": "f5bb723a02aff91d",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# save the tensor\n",
    "torch.save(data, \"../data/books/train_matrix.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T00:04:45.364655Z",
     "start_time": "2024-03-31T00:04:45.347120Z"
    }
   },
   "id": "30e911882b9de1a",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../data/books/test.json\", \"r\") as f:\n",
    "    test = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T00:32:30.993302Z",
     "start_time": "2024-03-31T00:32:30.983714Z"
    }
   },
   "id": "b8ea0dd61b1db7c4",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# create 2000 user dict\n",
    "user_dict = {}\n",
    "for i in range(2000):\n",
    "    user_dict[i] = test[str(i)]\n",
    "# save the user dict\n",
    "with open(\"../data/books/test.json\", \"w\") as f:\n",
    "    json.dump(user_dict, f)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T00:34:27.353081Z",
     "start_time": "2024-03-31T00:34:27.332623Z"
    }
   },
   "id": "f5c2657b1806267c",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../data/books/augmented_interactions_dict.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T22:42:18.588107Z",
     "start_time": "2024-04-05T22:42:18.570419Z"
    }
   },
   "id": "372c91cda2d20a1f",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# convert all lists items to int and save the dict\n",
    "mauvais = {}\n",
    "for key in data.keys():\n",
    "    if type(data[key][0]) != int or type(data[key][1]) != int:\n",
    "        mauvais[key] = data[key]\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-05T22:42:28.467293Z",
     "start_time": "2024-04-05T22:42:28.459281Z"
    }
   },
   "id": "bc97fda7c42e5152",
   "execution_count": 51
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

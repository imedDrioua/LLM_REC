{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-28T00:09:52.566656Z",
     "start_time": "2024-03-28T00:09:51.653895Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "class BooksDataset:\n",
    "\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.train_matrix = pd.read_pickle(f'{data_dir}/train_matrix.pkl')\n",
    "        self.images = np.load(f'{data_dir}/embed_image.npy')\n",
    "        self.text = np.load(f'{data_dir}/embed_text.npy')\n",
    "        self.user_profiles = np.load(f'{data_dir}/users_profiles_embeddings.npy')\n",
    "        self.books_attributes = np.load(f'{data_dir}/books_attributes_embeddings.npy')\n",
    "        with open(f'{data_dir}/train.json', 'r') as f:\n",
    "            self.train_dict = json.load(f)\n",
    "        with open(f'{data_dir}/test.json', 'r') as f:\n",
    "            self.test_dict = json.load(f)\n",
    "        with open(f'{data_dir}/validation.json', 'r') as f:\n",
    "            self.val_dict = json.load(f)\n",
    "        # create a dict to map each dataset name to its corresponding data\n",
    "        self.datasets = {\n",
    "            'train': self.train_matrix,\n",
    "            'images': self.images,\n",
    "            'text': self.text,\n",
    "            'user_profiles': self.user_profiles,\n",
    "            'books_attributes': self.books_attributes,\n",
    "            'train_dict': self.train_dict,\n",
    "            'test_dict': self.test_dict,\n",
    "            'val_dict': self.val_dict\n",
    "        }\n",
    "        \n",
    "    # return the length of all the datasets as dictionary    \n",
    "    def __len__(self):\n",
    "        return {k: len(v) for k,v in self.datasets.items()}\n",
    "    \n",
    "    # return the dataset by name\n",
    "    def get_dataset(self,dataset):\n",
    "        \"\"\"\n",
    "        Return the dataset by name\n",
    "        :param dataset: dataset name\n",
    "        :type dataset: str\n",
    "        :return: dataset\n",
    "        :rtype: numpy.ndarray\n",
    "        \"\"\"\n",
    "        return self.datasets[dataset]\n",
    "    \n",
    "    # return all the datasets\n",
    "    def get_all_datasets(self):\n",
    "        \"\"\"\n",
    "        Return all the datasets\n",
    "        :return: all the datasets defined in the class\n",
    "        :rtype: dict\n",
    "        \"\"\"\n",
    "        return self.datasets\n",
    "    \n",
    "    # sample n_users from the train dataset, and return the users, positive and negative books\n",
    "    def sample(self, n_users):\n",
    "        \"\"\"\n",
    "        Sample n_users from the train dataset, and return the users, positive and negative books\n",
    "        :param n_users: number of users to sample \n",
    "        :type n_users: int\n",
    "        :return:  users list, positive books list, negative books list\n",
    "        :rtype: list, list, list\n",
    "        \"\"\"\n",
    "        users = []\n",
    "        pos_books = []\n",
    "        neg_books = []\n",
    "        for i in range(n_users):\n",
    "            user = self.train_dict[str(i)]\n",
    "            pos_book = np.random.choice(self.train_dict[user])\n",
    "            while True:\n",
    "                neg_book = np.random.choice(self.train_dict.values())\n",
    "                if neg_book not in self.train_dict[user]:\n",
    "                    break\n",
    "            users.append(user)\n",
    "            pos_books.append(pos_book)\n",
    "            neg_books.append(neg_book)\n",
    "\n",
    "        return users, pos_books, neg_books\n",
    "\n",
    "    def describe(self):\n",
    "        \"\"\"\n",
    "        Return the shape of all the datasets, number of interractions and the sparsity of the train matrix\n",
    "      \n",
    "        \"\"\"\n",
    "        # get the shape of all the datasets (dictionaries need special handling)\n",
    "        shape = {k: v.shape if isinstance(v, np.ndarray) else len(v) for k,v in self.datasets.items()}\n",
    "        # get the number of interactions in the train matrix\n",
    "        n_interactions = np.count_nonzero(self.train_matrix)\n",
    "        # get the sparsity of the train matrix (number of missing interactions / total interactions)\n",
    "        sparsity = 1 - n_interactions / (self.train_matrix.shape[0] * self.train_matrix.shape[1])\n",
    "        # print the results as two columns\n",
    "        print(f\"{'Dataset':<20}{'Shape':<20}\")\n",
    "        print('-' * 40)\n",
    "        for k,v in shape.items():\n",
    "            print(f\"{k:<20}{v}\")\n",
    "            \n",
    "        print(f\"\\nNumber of interactions: {n_interactions}\")\n",
    "        print(f\"Sparsity: {sparsity:.2%}\")\n",
    "        \n",
    "      "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T00:29:38.807251Z",
     "start_time": "2024-03-28T00:29:38.797933Z"
    }
   },
   "id": "970999d1551474d8",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset             Shape               \n",
      "----------------------------------------\n",
      "train               14790\n",
      "images              (33962, 1024)\n",
      "text                (33962, 1024)\n",
      "user_profiles       (14790, 768)\n",
      "books_attributes    (33962, 768)\n",
      "train_dict          14790\n",
      "test_dict           14790\n",
      "val_dict            14790\n",
      "\n",
      "Number of interactions: 449114\n",
      "Sparsity: 99.91%\n"
     ]
    }
   ],
   "source": [
    "# test the class\n",
    "data_dir = '../data/books'\n",
    "dataset = BooksDataset(data_dir)\n",
    "dataset.describe()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T00:29:50.216252Z",
     "start_time": "2024-03-28T00:29:39.289232Z"
    }
   },
   "id": "dfa73d99575f33",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import torch\n",
    "n_users = dataset.get_dataset('train').shape[0]\n",
    "# create a function that converts the train dicti to A_tilda matrix\n",
    "def get_A_tilda(self):\n",
    "    R = sp.dok_matrix((self.n_users, self.n_items), dtype = np.float32)\n",
    "    R[self.dataset[\"user_id_idx\"] , self.data['item_id_idx']] = 1.0\n",
    "\n",
    "    adj_mat = sp.dok_matrix(\n",
    "        (self.n_users + self.n_items, self.n_users + self.n_items), dtype=np.float32\n",
    "    )\n",
    "    adj_mat = adj_mat.tolil()\n",
    "    R = R.tolil()\n",
    "\n",
    "    adj_mat[: n_users, n_users :] = R\n",
    "    adj_mat[n_users :, : n_users] = R.T\n",
    "    adj_mat = adj_mat.todok()\n",
    "\n",
    "    rowsum = np.array(adj_mat.sum(1))\n",
    "    d_inv = np.power(rowsum + 1e-9, -0.5).flatten()\n",
    "    d_inv[np.isinf(d_inv)] = 0.0\n",
    "    d_mat_inv = sp.diags(d_inv)\n",
    "    norm_adj_mat = d_mat_inv.dot(adj_mat)\n",
    "    norm_adj_mat = norm_adj_mat.dot(d_mat_inv)\n",
    "\n",
    "    # Below Code is toconvert the dok_matrix to sparse tensor.\n",
    "\n",
    "    norm_adj_mat_coo = norm_adj_mat.tocoo().astype(np.float32)\n",
    "    values = norm_adj_mat_coo.data\n",
    "    indices = np.vstack((norm_adj_mat_coo.row, norm_adj_mat_coo.col))\n",
    "\n",
    "    i = torch.LongTensor(indices)\n",
    "    v = torch.FloatTensor(values)\n",
    "    shape = norm_adj_mat_coo.shape\n",
    "\n",
    "    norm_adj_mat_sparse_tensor = torch.sparse.FloatTensor(i, v, torch.Size(shape))\n",
    "\n",
    "    return norm_adj_mat_sparse_tensor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81c44f85fe7f61d6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
